{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBmRrmIs6Ki0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the KMNIST dataset\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'kmnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Convert the dataset to NumPy arrays\n",
        "def convert_to_numpy(dataset):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image, label in dataset:\n",
        "        images.append(image.numpy())\n",
        "        labels.append(label.numpy())\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "X_train, y_train = convert_to_numpy(ds_train)\n",
        "X_test, y_test = convert_to_numpy(ds_test)\n",
        "\n",
        "# Preprocess the data: Normalize pixel values between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images for RBF network input (28x28 -> 784)\n",
        "X_train_flat = X_train.reshape(-1, 28*28)  # (60000, 784)\n",
        "X_test_flat = X_test.reshape(-1, 28*28)    # (10000, 784)\n",
        "\n",
        "# One-hot encode the labels for classification (10 classes)\n",
        "y_train_oh = to_categorical(y_train, num_classes=10)\n",
        "y_test_oh = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Check the shapes\n",
        "print(\"X_train_flat shape:\", X_train_flat.shape)\n",
        "print(\"y_train_oh shape:\", y_train_oh.shape)\n",
        "print(\"X_test_flat shape:\", X_test_flat.shape)\n",
        "print(\"y_test_oh shape:\", y_test_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyF_0UKX2CXI",
        "outputId": "358f18dc-720b-430c-8394-878da797a3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_flat shape: (60000, 784)\n",
            "y_train_oh shape: (60000, 10)\n",
            "X_test_flat shape: (10000, 784)\n",
            "y_test_oh shape: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RBF layer with Gaussian function\n",
        "class RBFLayer:\n",
        "    def __init__(self, num_rbf_units, sigma):\n",
        "        self.num_rbf_units = num_rbf_units\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def rbf_function(self, X, centers):\n",
        "        dist = euclidean_distances(X, centers)\n",
        "        return np.exp(-dist**2 / (2 * self.sigma**2))\n",
        "\n",
        "# Define the architecture\n",
        "class RBFNetwork:\n",
        "    def __init__(self, num_rbf_units, input_size, num_classes, sigma):\n",
        "        self.rbf_layer = RBFLayer(num_rbf_units, sigma)\n",
        "        self.num_rbf_units = num_rbf_units\n",
        "        self.input_size = input_size\n",
        "        self.num_classes = num_classes\n",
        "        # Xavier/Glorot initialization for better stability\n",
        "        self.weights = np.random.randn(self.num_rbf_units, self.num_classes) * np.sqrt(2. / (self.num_rbf_units + self.num_classes))\n",
        "        self.bias = np.zeros(self.num_classes)\n",
        "\n",
        "    def predict(self, X, centers):\n",
        "        # Compute the hidden layer output (RBF)\n",
        "        G = self.rbf_layer.rbf_function(X, centers)\n",
        "        # Compute the output layer with softmax activation\n",
        "        logits = G.dot(self.weights) + self.bias\n",
        "        return self.softmax(logits)\n",
        "\n",
        "    def softmax(self, z):\n",
        "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "vN1QfC9K7JYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RBFTrainer:\n",
        "    def __init__(self, rbf_network, learning_rate=0.01, epochs=100, batch_size=64, reg_lambda=0.001):\n",
        "        self.rbf_network = rbf_network\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.reg_lambda = reg_lambda  # Regularization factor\n",
        "\n",
        "    def cross_entropy_loss(self, y_true, y_pred):\n",
        "        return -np.mean(np.sum(y_true * np.log(y_pred + 1e-8), axis=1))\n",
        "\n",
        "    def fit(self, X_train, y_train, centers):\n",
        "        num_samples = X_train.shape[0]\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            indices = np.arange(num_samples)\n",
        "            np.random.shuffle(indices)\n",
        "            X_train = X_train[indices]\n",
        "            y_train = y_train[indices]\n",
        "\n",
        "            for i in range(0, num_samples, self.batch_size):\n",
        "                X_batch = X_train[i:i+self.batch_size]\n",
        "                y_batch = y_train[i:i+self.batch_size]\n",
        "\n",
        "                predictions = self.rbf_network.predict(X_batch, centers)\n",
        "\n",
        "                loss = self.cross_entropy_loss(y_batch, predictions)\n",
        "\n",
        "                reg_loss = self.reg_lambda * np.sum(np.square(self.rbf_network.weights))\n",
        "                total_loss = loss + reg_loss\n",
        "\n",
        "                error = predictions - y_batch\n",
        "\n",
        "                G = self.rbf_network.rbf_layer.rbf_function(X_batch, centers)\n",
        "                grad_weights = G.T.dot(error) + self.reg_lambda * self.rbf_network.weights\n",
        "                self.rbf_network.weights -= self.learning_rate * grad_weights\n",
        "                self.rbf_network.bias -= self.learning_rate * np.sum(error, axis=0)\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f'Epoch {epoch+1}/{self.epochs}, Loss: {total_loss:.4f}')\n",
        "\n",
        "# Define the RBF network parameters\n",
        "num_rbf_units = 200  # Increased RBF units\n",
        "input_size = 784     # Input size (28x28 flattened)\n",
        "num_classes = 10     # Number of output classes\n",
        "sigma = 2.0          # Adjusted sigma\n",
        "\n",
        "# Instantiate the RBF network\n",
        "rbf_net = RBFNetwork(num_rbf_units=num_rbf_units, input_size=input_size, num_classes=num_classes, sigma=sigma)\n",
        "\n",
        "# Use K-means to determine the centers of RBF units\n",
        "kmeans = KMeans(n_clusters=num_rbf_units, random_state=42).fit(X_train_flat)\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "# Instantiate and train the RBF trainer using mini-batch gradient descent\n",
        "trainer = RBFTrainer(rbf_net, learning_rate=0.01, epochs=100, batch_size=64, reg_lambda=0.001)\n",
        "trainer.fit(X_train_flat, y_train_oh, centers)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred = rbf_net.predict(X_test_flat, centers)\n",
        "accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_test_oh, axis=1))\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QILrLPc-nUT",
        "outputId": "eb563142-0219-4aad-da62-a0327ee717c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 2.4702\n",
            "Epoch 20/100, Loss: 2.9727\n",
            "Epoch 30/100, Loss: 3.5500\n",
            "Epoch 40/100, Loss: 4.1034\n",
            "Epoch 50/100, Loss: 4.7505\n",
            "Epoch 60/100, Loss: 5.3412\n",
            "Epoch 70/100, Loss: 5.8234\n",
            "Epoch 80/100, Loss: 6.4078\n",
            "Epoch 90/100, Loss: 6.8919\n",
            "Epoch 100/100, Loss: 7.1989\n",
            "Test Accuracy: 33.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kR4wUl1L-rJD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}